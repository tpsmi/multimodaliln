{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Extraction and Text Recognition Notebook\n",
    "\n",
    "This notebook demonstrates how to extract images from a dataset using a trained YOLO model and perform text recognition on the extracted images. \n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we'll import the necessary libraries. Don't worry if you don't understand all of these - they're tools we'll use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO \n",
    "import torch  \n",
    "import numpy as np\n",
    "import glob\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model and Setting Up Directories\n",
    "\n",
    "Now, we'll load our trained YOLO model and set up the directories for our input and output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model (adjust the path to where your model is stored). You trained this model in the notebook of step 4\n",
    "model = YOLO('finetunedmodel.pt')\n",
    "\n",
    "# Directory containing your original images\n",
    "source = 'images'\n",
    "# Directory where extracted images will be saved\n",
    "output_folder = 'extractedimages'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Image Paths\n",
    "\n",
    "This step collects the paths of all images in our source directory. It looks for common image file types like .png, .jpg, and .jpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all images using a glob pattern\n",
    "image_extensions = ('*.png', '*.jpg', '*.jpeg')\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(f'{source}/**/{ext}', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Images\n",
    "\n",
    "This is the main part of our script. It processes the images in batches, uses our YOLO model to detect regions of interest, and extracts these regions as separate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store results\n",
    "data = []\n",
    "\n",
    "# Time tracking\n",
    "start_time = time.time()\n",
    "\n",
    "# Process images in batches\n",
    "batch_size = 8  # Adjust based on your system's memory capacity\n",
    "for i in range(0, len(image_paths), batch_size):\n",
    "    batch = image_paths[i:i + batch_size]\n",
    "    results = model(batch)\n",
    "    for img_path, result in zip(batch, results):\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "            for bbox_info in result.boxes:\n",
    "                if bbox_info.cls == 0:\n",
    "                    bbox = bbox_info.xyxy.cpu().detach().numpy().flatten()\n",
    "                    x1, y1, x2, y2 = map(int, bbox)\n",
    "                    cropped_img = img.crop((x1, y1, x2, y2))\n",
    "                    cropped_name = f\"{os.path.splitext(os.path.basename(img_path))[0]}_{x1}_{y1}_{x2}_{y2}.png\"\n",
    "                    cropped_img_path = os.path.join(output_folder, cropped_name)\n",
    "                    cropped_img.save(cropped_img_path)\n",
    "                    data.append({\n",
    "                        'original_filename': os.path.basename(img_path),\n",
    "                        'cropped_filename': cropped_name,\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'confidence': float(bbox_info.conf)\n",
    "                    })\n",
    "\n",
    "# Save metadata to a CSV file for further processing\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('cropped_images_metadata.csv', index=False)\n",
    "end_time = time.time()\n",
    "print(f\"Extraction process completed in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Recognition\n",
    "\n",
    "Now that we've extracted our images, we'll perform text recognition on them. This process involves checking the readability of the text, enhancing the image quality, and then using OCR (Optical Character Recognition) to extract the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cropped_images_metadata.csv')\n",
    "\n",
    "# Function to check text readability and correct orientation for a specific area of the image\n",
    "def check_text_readability(img):\n",
    "    img_width, img_height = img.size\n",
    "    caption_area = img.crop((0, int(img_height * 0.95), img_width, img_height))\n",
    "\n",
    "    # Try OCR at different rotations: 0, 90, 180, 270 degrees\n",
    "    for angle in [0, 90, 180, 270]:\n",
    "        test_img = caption_area.rotate(angle, expand=True)\n",
    "        test_text = pytesseract.image_to_string(test_img, config='--psm 7')\n",
    "        if any(char.isalpha() for char in test_text):\n",
    "            if angle != 0:\n",
    "                return img.rotate(angle, expand=True)\n",
    "            return img\n",
    "    return img\n",
    "\n",
    "# Function to process each image and measure processing time\n",
    "def process_image(row):\n",
    "    cropped_img_path = os.path.join(output_folder, row['cropped_filename'])\n",
    "    start_time = time.time()  # Start time measurement\n",
    "\n",
    "    try:\n",
    "        with Image.open(cropped_img_path) as img:\n",
    "            img = check_text_readability(img)\n",
    "            img_width, img_height = img.size\n",
    "            caption_img = img.crop((0, int(img_height * 0.95), img_width, img_height))\n",
    "            gray_img = caption_img.convert('L')\n",
    "            contrast_enhancer = ImageEnhance.Contrast(gray_img)\n",
    "            enhanced_img = contrast_enhancer.enhance(2)\n",
    "            threshold = 128\n",
    "            binarized_img = enhanced_img.point(lambda p: p > threshold and 255)\n",
    "            text = pytesseract.image_to_string(binarized_img, config='--psm 6')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {cropped_img_path}: {e}\")\n",
    "        text = \"\"\n",
    "\n",
    "    end_time = time.time()  # End time measurement\n",
    "    processing_time = end_time - start_time\n",
    "    return text.strip(), processing_time\n",
    "\n",
    "# Parallel processing and collect times\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = list(executor.map(process_image, df.to_dict('records')))\n",
    "\n",
    "# Unpack results and processing times\n",
    "text_data, times = zip(*results)\n",
    "\n",
    "# Add extracted text to the DataFrame\n",
    "df['extracted_text'] = text_data\n",
    "df.to_csv('final_output_with_text.csv', index=False)\n",
    "\n",
    "# Calculate average time per image\n",
    "total_time = sum(times)\n",
    "average_time = sum(times) / len(times)\n",
    "print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "print(f\"Average processing time per image: {average_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated how to:\n",
    "1. Load a trained YOLO model\n",
    "2. Process a batch of images to extract regions of interest\n",
    "3. Perform text recognition on the extracted images\n",
    "4. Save the results in a CSV file\n",
    "\n",
    "The final output is saved in 'final_output_with_text.csv', which contains information about each extracted image and its recognized text.\n",
    "\n",
    "Remember to adjust file paths and model names as necessary for your specific setup. Happy image processing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
